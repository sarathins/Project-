{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5468ae9d",
   "metadata": {},
   "source": [
    "Deep Q-Learning (DQL) is a variant of Q-Learning that uses deep neural networks to approximate the Q-function. Instead of maintaining a table (Q-table) to store Q-values for each state-action pair, DQL uses a neural network to approximate the Q-values.\n",
    "\n",
    "### Deep Q-Learning (DQL) for Hangman\n",
    "\n",
    "#### Components:\n",
    "\n",
    "##### State Representation:\n",
    "Current word pattern\n",
    "Guessed letters\n",
    "Remaining incorrect guesses\n",
    "\n",
    "##### Action Space:\n",
    "All possible letters to guess\n",
    "\n",
    "##### Reward Function:\n",
    "+1 for each correct guess\n",
    "-1 for each incorrect guess\n",
    "+5 for completing the word\n",
    "\n",
    "##### Deep Q-Learning Algorithm:\n",
    "Initialize a neural network to approximate the Q-function\n",
    "Update the neural network using the Q-learning update rule\n",
    "Use an epsilon-greedy policy for action selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e06c68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e4b174b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SONY\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "C:\\Users\\SONY\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "import random\n",
    "import numpy as np\n",
    "import gc\n",
    "import concurrent.futures\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f10e742",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HangmanAPI:\n",
    "    def __init__(self, access_token):\n",
    "        self.access_token = access_token\n",
    "        self.base_url = \"https://api.example.com/hangman\"  # Replace with actual API endpoint\n",
    "\n",
    "    def start_game(self, practice=True, verbose=True):\n",
    "        # Implement starting a new game via API\n",
    "        pass\n",
    "\n",
    "    def guess_letter(self, game_id, letter):\n",
    "        # Implement guessing a letter via API\n",
    "        pass\n",
    "\n",
    "    def my_status(self):\n",
    "        # Implement getting player's current game status via API\n",
    "        pass\n",
    "\n",
    "# Define DQLAgent class for Deep Q-Learning\n",
    "class DQLAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.model = self.build_dql_model()\n",
    "\n",
    "    def build_dql_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(12, input_dim=self.state_size, activation='relu'))  # Reduced neurons\n",
    "        model.add(Dense(12, activation='relu'))  # Reduced neurons\n",
    "        model.add(Dense(self.action_size, activation='linear'))\n",
    "        model.compile(loss='mse', optimizer=Adam(learning_rate=0.001))\n",
    "        return model\n",
    "\n",
    "    def act(self, state):\n",
    "        q_values = self.model.predict(state)\n",
    "        available_actions = np.where(q_values >= 0)[1]\n",
    "\n",
    "        if len(available_actions) == 0:\n",
    "            return None\n",
    "\n",
    "        action = np.argmax(q_values[0, available_actions])\n",
    "        return action\n",
    "\n",
    "    def train(self, states, target_q_values):\n",
    "        self.model.fit(states, target_q_values, epochs=1, verbose=0)\n",
    "        gc.collect()  # Garbage collect to free up memory\n",
    "\n",
    "    def train_batch(self, state_batch, target_q_values_batch):\n",
    "        self.model.fit(state_batch, target_q_values_batch, epochs=1, verbose=0)\n",
    "        gc.collect()  # Garbage collect to free up memory\n",
    "\n",
    "# Define HangmanGame class\n",
    "class HangmanGame:\n",
    "    def __init__(self, api, file_path):\n",
    "        self.api = api\n",
    "        self.dictionary = self.load_and_validate_dictionary(file_path)\n",
    "        self.state_size = 52\n",
    "        self.action_size = 26\n",
    "        self.agent = DQLAgent(self.state_size, self.action_size)\n",
    "        self.train_memory = {}\n",
    "\n",
    "    def load_and_validate_dictionary(self, file_path):\n",
    "        valid_words = []\n",
    "        with open(file_path, 'r') as file:\n",
    "            for line in file:\n",
    "                word = line.strip().lower()\n",
    "                if word.isalpha():\n",
    "                    valid_words.append(word)\n",
    "        return valid_words\n",
    "\n",
    "    def split_data(self, test_size=0.2):\n",
    "        train_words, test_words = train_test_split(self.dictionary, test_size=test_size, random_state=42)\n",
    "        return train_words, test_words\n",
    "\n",
    "    def word_to_state(self, word):\n",
    "        word_vector = [0] * 26\n",
    "        for letter in word:\n",
    "            if letter.isalpha():\n",
    "                index = ord(letter) - ord('a')\n",
    "                word_vector[index] = 1\n",
    "\n",
    "        letters_vector = [0] * 26\n",
    "        state = word_vector + letters_vector\n",
    "        return np.array([state])\n",
    "\n",
    "    def word_to_target(self, word):\n",
    "        target = [0] * 26\n",
    "        for letter in word:\n",
    "            if letter.isalpha():\n",
    "                index = ord(letter) - ord('a')\n",
    "                target[index] = 1\n",
    "        return target\n",
    "\n",
    "    def train_agent(self, train_words, batch_size=32):\n",
    "        for word in train_words:\n",
    "            if word not in self.train_memory:\n",
    "                state, action, reward, next_state = self.process_word(word)\n",
    "                self.train_memory[word] = (state.flatten(), action, reward, next_state)\n",
    "\n",
    "        train_words_batches = [train_words[i:i+batch_size] for i in range(0, len(train_words), batch_size)]\n",
    "\n",
    "        for batch in train_words_batches:\n",
    "            states_batch = []\n",
    "            target_q_values_batch = []\n",
    "\n",
    "            for word in batch:\n",
    "                state, action, reward, next_state = self.train_memory[word]\n",
    "                states_batch.append(state)\n",
    "\n",
    "                target_q_values = self.agent.model.predict(state)\n",
    "                max_next_q_value = np.max(self.agent.model.predict(next_state)) if next_state is not None else 0\n",
    "                target_q_values[0, action] = reward + max_next_q_value\n",
    "                target_q_values_batch.append(target_q_values.flatten())\n",
    "\n",
    "            states_batch = np.array(states_batch)\n",
    "            target_q_values_array = np.array(target_q_values_batch)\n",
    "            self.agent.train_batch(states_batch, target_q_values_array)\n",
    "            del states_batch, target_q_values_array\n",
    "            gc.collect()  # Garbage collect to fr\n",
    "\n",
    "    def process_word(self, word):\n",
    "        state = self.word_to_state(word)\n",
    "        action = self.agent.act(state)\n",
    "        reward = self.calculate_reward(word, action)\n",
    "\n",
    "        next_word = random.choice(self.dictionary)\n",
    "        next_state = self.word_to_state(next_word) if next_word != word else None\n",
    "\n",
    "        return state, action, reward, next_state\n",
    "\n",
    "    def calculate_reward(self, word, action):\n",
    "        if action is None:\n",
    "            return -1\n",
    "        letter = chr(action + ord('a'))\n",
    "        if letter in word:\n",
    "            return 1\n",
    "        else:\n",
    "            return -1\n",
    "\n",
    "    def evaluate_agent(self, test_words):\n",
    "        correct_predictions = 0\n",
    "        total_predictions = 0\n",
    "\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            futures = [executor.submit(self.evaluate_word, word) for word in test_words]\n",
    "\n",
    "            for future in concurrent.futures.as_completed(futures):\n",
    "                correct_predictions += future.result()\n",
    "                total_predictions += 1\n",
    "\n",
    "        accuracy = (correct_predictions / total_predictions) * 100\n",
    "        print(f\"Accuracy on test data: {accuracy:.2f}%\")\n",
    "\n",
    "    def evaluate_word(self, word):\n",
    "        state = self.word_to_state(''.join(['_' * len(word)]))\n",
    "        while True:\n",
    "            action = self.agent.act(state)\n",
    "            if action is None:\n",
    "                return 0\n",
    "\n",
    "            letter = chr(action + ord('a'))\n",
    "            if letter in word:\n",
    "                return 1\n",
    "\n",
    "            state[0, action] = -1\n",
    "\n",
    "    def save_train_memory(self, file_path):\n",
    "        with open(file_path, 'w') as file:\n",
    "            json.dump(self.train_memory, file)\n",
    "\n",
    "    def load_train_memory(self, file_path):\n",
    "        with open(file_path, 'r') as file:\n",
    "            self.train_memory = json.load(file)\n",
    "\n",
    "        # Convert string keys back to tuples if needed\n",
    "        self.train_memory = {tuple(map(int, k.split(','))): v for k, v in self.train_memory.items()}\n",
    "\n",
    "    def predict_letters_for_games(self, num_games=1000):\n",
    "        for _ in range(num_games):\n",
    "            game_id = self.api.start_game()  # Start a new game\n",
    "            game_over = False\n",
    "            while not game_over:\n",
    "                current_word = self.api.my_status()['word']\n",
    "                state = self.word_to_state(current_word)\n",
    "                letter = self.predict_letter(state)\n",
    "                if letter:\n",
    "                    response = self.api.guess_letter(game_id, letter)\n",
    "                    if response['status'] == 'success':\n",
    "                        if response['gameStatus'] == 'lost':\n",
    "                            game_over = True\n",
    "                            self.losses += 1\n",
    "                        elif response['gameStatus'] == 'won':\n",
    "                            game_over = True\n",
    "                            self.wins += 1\n",
    "                        else:\n",
    "                            # Game is ongoing, continue guessing\n",
    "                            pass\n",
    "                    else:\n",
    "                        print(\"Failed to guess letter:\", letter)\n",
    "                        break\n",
    "                else:\n",
    "                    print(\"No letter predicted for the current state.\")\n",
    "                    break\n",
    "\n",
    "    def predict_letter(self, state):\n",
    "          return self.agent.predict_letter(state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c155a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    access_token = \"0e9732ec39694400482388c882b6d1\"  # Replace with actual access token\n",
    "    api = HangmanAPI(access_token)\n",
    "    file_path = \"C:\\\\Users\\\\SONY\\\\Downloads\\\\words_250000_train.txt\"  # Path to your dictionary file\n",
    "    hangman_game = HangmanGame(api, file_path)\n",
    "    train_words, test_words = hangman_game.split_data(test_size=0.2)\n",
    "\n",
    "    # Train the agent\n",
    "    hangman_game.train_agent(train_words)\n",
    "\n",
    "    # Evaluate the agent\n",
    "    hangman_game.evaluate_agent(test_words)\n",
    "\n",
    "    # Run 1000 games and evaluate accuracy\n",
    "    hangman_game.predict_letters_for_games(num_games=1000)\n",
    "    print(f\"Accuracy on 1000 games: {hangman_game.get_accuracy()}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "401c0db8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0669fa38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fe5cca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956d18c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
